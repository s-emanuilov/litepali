{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a complete workflow for downloading PDFs, parsing them, creating a LitePali index, and performing searches. It's designed to run from start to finish without requiring user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litepali in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.0.5)\n",
      "Requirement already satisfied: pdf2image in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.17.0)\n",
      "Requirement already satisfied: PyPDF2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: colpali-engine<0.4.0,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litepali) (0.3.0)\n",
      "Requirement already satisfied: pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pdf2image) (10.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: gputil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from colpali-engine<0.4.0,>=0.3.0->litepali) (1.4.0)\n",
      "Requirement already satisfied: numpy<2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from colpali-engine<0.4.0,>=0.3.0->litepali) (1.26.4)\n",
      "Requirement already satisfied: peft<0.12.0,>=0.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from colpali-engine<0.4.0,>=0.3.0->litepali) (0.11.1)\n",
      "Requirement already satisfied: torch>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from colpali-engine<0.4.0,>=0.3.0->litepali) (2.2.1+cu121)\n",
      "Requirement already satisfied: transformers>=4.41.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from colpali-engine<0.4.0,>=0.3.0->litepali) (4.44.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft<0.12.0,>=0.11.0->colpali-engine<0.4.0,>=0.3.0->litepali) (24.1)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft<0.12.0,>=0.11.0->colpali-engine<0.4.0,>=0.3.0->litepali) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft<0.12.0,>=0.11.0->colpali-engine<0.4.0,>=0.3.0->litepali) (6.0.2)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft<0.12.0,>=0.11.0->colpali-engine<0.4.0,>=0.3.0->litepali) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft<0.12.0,>=0.11.0->colpali-engine<0.4.0,>=0.3.0->litepali) (0.34.2)\n",
      "Requirement already satisfied: safetensors in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft<0.12.0,>=0.11.0->colpali-engine<0.4.0,>=0.3.0->litepali) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft<0.12.0,>=0.11.0->colpali-engine<0.4.0,>=0.3.0->litepali) (0.24.7)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (4.12.2)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (1.13.2)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (3.3)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (12.6.68)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.41.1->colpali-engine<0.4.0,>=0.3.0->litepali) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.41.1->colpali-engine<0.4.0,>=0.3.0->litepali) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=2.2.0->colpali-engine<0.4.0,>=0.3.0->litepali) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install litepali pdf2image PyPDF2 requests\n",
    "\n",
    "# This cell installs the necessary libraries:\n",
    "# - litepali: Your custom library for document retrieval\n",
    "# - pdf2image: For converting PDF pages to images\n",
    "# - PyPDF2: For parsing PDF metadata\n",
    "# - requests: For downloading PDFs from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import requests\n",
    "import PyPDF2\n",
    "from pdf2image import convert_from_bytes\n",
    "from litepali import LitePali, ImageFile\n",
    "\n",
    "# This cell imports the necessary libraries and modules we'll use throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PDF URLs and create base directory\n",
    "pdf_urls = [\n",
    "    \"https://arxiv.org/pdf/2403.09611.pdf\",\n",
    "    \"https://arxiv.org/pdf/2103.00020.pdf\",\n",
    "    \"https://arxiv.org/pdf/2407.01449.pdf\"\n",
    "]\n",
    "base_dir = os.path.join(os.getcwd(), \"litepali_data\")\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# This cell defines the URLs of the PDFs we want to process and creates a base directory\n",
    "# inside the current notebook folder to store our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded PDFs: ['/teamspace/studios/this_studio/litepali_data/2403.09611/2403.09611.pdf', '/teamspace/studios/this_studio/litepali_data/2103.00020/2103.00020.pdf', '/teamspace/studios/this_studio/litepali_data/2407.01449/2407.01449.pdf']\n"
     ]
    }
   ],
   "source": [
    "# Download PDFs\n",
    "def download_pdf(url, save_dir):\n",
    "    response = requests.get(url)\n",
    "    filename = url.split('/')[-1]\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    return save_path\n",
    "\n",
    "downloaded_paths = []\n",
    "for url in pdf_urls:\n",
    "    url_dir = os.path.join(base_dir, url.split('/')[-1].replace('.pdf', ''))\n",
    "    os.makedirs(url_dir, exist_ok=True)\n",
    "    downloaded_paths.append(download_pdf(url, url_dir))\n",
    "\n",
    "print(\"Downloaded PDFs:\", downloaded_paths)\n",
    "\n",
    "# This cell defines a function to download PDFs and then downloads each PDF from the specified URLs.\n",
    "# Each PDF is saved in its own directory within the base directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed PDFs: [{'pdf_path': '/teamspace/studios/this_studio/litepali_data/2403.09611/2403.09611.pdf', 'images': ['/teamspace/studios/this_studio/litepali_data/2403.09611/page_1.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_2.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_3.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_4.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_5.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_6.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_7.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_8.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_9.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_10.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_11.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_12.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_13.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_14.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_15.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_16.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_17.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_18.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_19.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_20.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_21.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_22.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_23.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_24.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_25.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_26.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_27.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_28.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_29.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_30.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_31.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_32.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_33.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_34.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_35.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_36.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_37.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_38.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_39.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_40.jpg', '/teamspace/studios/this_studio/litepali_data/2403.09611/page_41.jpg'], 'metadata': {'/Author': '', '/CreationDate': 'D:20240422000405Z', '/Creator': 'LaTeX with hyperref', '/Keywords': '', '/ModDate': 'D:20240422000405Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', '/Producer': 'pdfTeX-1.40.25', '/Subject': '', '/Title': '', '/Trapped': '/False'}, 'num_pages': 41}, {'pdf_path': '/teamspace/studios/this_studio/litepali_data/2103.00020/2103.00020.pdf', 'images': ['/teamspace/studios/this_studio/litepali_data/2103.00020/page_1.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_2.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_3.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_4.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_5.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_6.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_7.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_8.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_9.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_10.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_11.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_12.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_13.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_14.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_15.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_16.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_17.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_18.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_19.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_20.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_21.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_22.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_23.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_24.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_25.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_26.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_27.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_28.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_29.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_30.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_31.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_32.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_33.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_34.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_35.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_36.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_37.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_38.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_39.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_40.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_41.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_42.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_43.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_44.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_45.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_46.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_47.jpg', '/teamspace/studios/this_studio/litepali_data/2103.00020/page_48.jpg'], 'metadata': {'/Author': 'Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever', '/CreationDate': 'D:20210302022406Z', '/Creator': 'LaTeX with hyperref', '/Keywords': '', '/ModDate': 'D:20210302022406Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', '/Producer': 'pdfTeX-1.40.21', '/Subject': 'Proceedings of the International Conference on Machine Learning 2020', '/Title': 'Learning Transferable Visual Models From Natural Language Supervision', '/Trapped': '/False'}, 'num_pages': 48}, {'pdf_path': '/teamspace/studios/this_studio/litepali_data/2407.01449/2407.01449.pdf', 'images': ['/teamspace/studios/this_studio/litepali_data/2407.01449/page_1.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_2.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_3.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_4.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_5.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_6.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_7.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_8.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_9.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_10.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_11.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_12.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_13.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_14.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_15.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_16.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_17.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_18.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_19.jpg', '/teamspace/studios/this_studio/litepali_data/2407.01449/page_20.jpg'], 'metadata': {'/Author': '', '/CreationDate': 'D:20240703004816Z', '/Creator': 'LaTeX with hyperref', '/Keywords': '', '/ModDate': 'D:20240703004816Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', '/Producer': 'pdfTeX-1.40.25', '/Subject': '', '/Title': '', '/Trapped': '/False'}, 'num_pages': 20}]\n"
     ]
    }
   ],
   "source": [
    "# Parse PDFs and convert to images\n",
    "def parse_pdf(pdf_path):\n",
    "    images = []\n",
    "    metadata = {}\n",
    "    \n",
    "    # Extract metadata\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        metadata = reader.metadata\n",
    "        num_pages = len(reader.pages)\n",
    "    \n",
    "    # Convert pages to images\n",
    "    pdf_images = convert_from_bytes(open(pdf_path, 'rb').read())\n",
    "    \n",
    "    pdf_dir = os.path.dirname(pdf_path)\n",
    "    for i, img in enumerate(pdf_images):\n",
    "        img_path = os.path.join(pdf_dir, f\"page_{i+1}.jpg\")\n",
    "        img.save(img_path, 'JPEG')\n",
    "        images.append(img_path)\n",
    "    \n",
    "    return images, metadata, num_pages\n",
    "\n",
    "parsed_pdfs = []\n",
    "for pdf_path in downloaded_paths:\n",
    "    images, metadata, num_pages = parse_pdf(pdf_path)\n",
    "    parsed_pdfs.append({\n",
    "        'pdf_path': pdf_path,\n",
    "        'images': images,\n",
    "        'metadata': metadata,\n",
    "        'num_pages': num_pages\n",
    "    })\n",
    "\n",
    "print(\"Parsed PDFs:\", parsed_pdfs)\n",
    "\n",
    "# This cell defines a function to parse PDFs, extract metadata, and convert pages to images.\n",
    "# It then applies this function to each downloaded PDF, saving images in the PDF's directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LitePali and add images\n",
    "litepali = LitePali()\n",
    "\n",
    "for pdf in parsed_pdfs:\n",
    "    for i, img_path in enumerate(pdf['images']):\n",
    "        litepali.add(ImageFile(\n",
    "            path=img_path,\n",
    "            document_id=os.path.basename(pdf['pdf_path']),\n",
    "            page_id=i+1,\n",
    "            metadata={\n",
    "                'title': pdf['metadata'].get('/Title', ''),\n",
    "                'author': pdf['metadata'].get('/Author', ''),\n",
    "                'num_pages': pdf['num_pages']\n",
    "            }\n",
    "        ))\n",
    "\n",
    "# This cell initializes LitePali and adds each image from the parsed PDFs to the index.\n",
    "# The document_id is set to the PDF filename, and page_id is set to the page number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d89860f556b4da0b80021d6ad612c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1: 4/109 images\n",
      "Processed batch 2: 8/109 images\n",
      "Processed batch 3: 12/109 images\n",
      "Processed batch 4: 16/109 images\n",
      "Processed batch 5: 20/109 images\n",
      "Processed batch 6: 24/109 images\n",
      "Processed batch 7: 28/109 images\n",
      "Processed batch 8: 32/109 images\n",
      "Processed batch 9: 36/109 images\n",
      "Processed batch 10: 40/109 images\n",
      "Processed batch 11: 44/109 images\n",
      "Processed batch 12: 48/109 images\n",
      "Processed batch 13: 52/109 images\n",
      "Processed batch 14: 56/109 images\n",
      "Processed batch 15: 60/109 images\n",
      "Processed batch 16: 64/109 images\n",
      "Processed batch 17: 68/109 images\n",
      "Processed batch 18: 72/109 images\n",
      "Processed batch 19: 76/109 images\n",
      "Processed batch 20: 80/109 images\n",
      "Processed batch 21: 84/109 images\n",
      "Processed batch 22: 88/109 images\n",
      "Processed batch 23: 92/109 images\n",
      "Processed batch 24: 96/109 images\n",
      "Processed batch 25: 100/109 images\n",
      "Processed batch 26: 104/109 images\n",
      "Processed batch 27: 108/109 images\n",
      "Processed batch 28: 109/109 images\n",
      "Finished processing. Total images processed: 109\n",
      "Index created successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_images': 109,\n",
       " 'processed_images': 109,\n",
       " 'unique_documents': 3,\n",
       " 'image_extensions': ['.jpg']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process images and create index\n",
    "litepali.process(batch_size=4)\n",
    "print(\"Index created successfully\")\n",
    "litepali.index_stats()\n",
    "\n",
    "# This cell processes the added images and creates the LitePali index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index saved to /teamspace/studios/this_studio/litepali_data/litepali_index\n",
      "Index saved to /teamspace/studios/this_studio/litepali_data/litepali_index\n"
     ]
    }
   ],
   "source": [
    "# Save the index\n",
    "index_path = os.path.join(base_dir, \"litepali_index\")\n",
    "litepali.save_index(index_path)\n",
    "print(f\"Index saved to {index_path}\")\n",
    "\n",
    "# This cell saves the created index to a file in the base directory for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index loaded from /teamspace/studios/this_studio/litepali_data/litepali_index\n",
      "Index loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load the index (simulating a new session)\n",
    "new_litepali = LitePali()\n",
    "new_litepali.load_index(index_path)\n",
    "print(\"Index loaded successfully\")\n",
    "\n",
    "# This cell demonstrates how to load a previously saved index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What is ColPali?\n",
      "Document: 2407.01449.pdf, Page: 1, Score: 14.75\n",
      "Document: 2407.01449.pdf, Page: 6, Score: 14.125\n",
      "Document: 2407.01449.pdf, Page: 2, Score: 13.5625\n",
      "\n",
      "Query: Explain the concept of vision language models\n",
      "Document: 2403.09611.pdf, Page: 17, Score: 14.75\n",
      "Document: 2407.01449.pdf, Page: 1, Score: 14.5625\n",
      "Document: 2407.01449.pdf, Page: 3, Score: 14.375\n",
      "\n",
      "Query: How does MM1 compare to other multimodal models?\n",
      "Document: 2403.09611.pdf, Page: 15, Score: 15.8125\n",
      "Document: 2403.09611.pdf, Page: 1, Score: 15.75\n",
      "Document: 2403.09611.pdf, Page: 17, Score: 15.5625\n",
      "\n",
      "Query: What is CLIP and where I can use it?\n",
      "Document: 2103.00020.pdf, Page: 20, Score: 17.375\n",
      "Document: 2103.00020.pdf, Page: 27, Score: 17.125\n",
      "Document: 2407.01449.pdf, Page: 11, Score: 17.0\n"
     ]
    }
   ],
   "source": [
    "# Perform searches\n",
    "queries = [\n",
    "    \"What is ColPali?\",\n",
    "    \"Explain the concept of vision language models\",\n",
    "    \"How does MM1 compare to other multimodal models?\",\n",
    "    \"What is CLIP and where I can use it?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    results = new_litepali.search(query, k=3)\n",
    "    for result in results:\n",
    "        print(f\"Document: {result['image'].document_id}, Page: {result['image'].page_id}, Score: {result['score']}\")\n",
    "\n",
    "# This cell performs searches using sample queries and prints the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| PDF Path | Title |\n",
       "|----------|-------|\n",
       "| 2403.09611.pdf | MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training |\n",
       "| 2103.00020.pdf | Learning Transferable Visual Models From Natural Language Supervision |\n",
       "| 2407.01449.pdf | ColPali: Efficient Document Retrieval with Vision Language Models |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FYI Table for PDF Information\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "table = \"\"\"\n",
    "| PDF path | Title |\n",
    "|----------|-------|\n",
    "| 2403.09611.pdf | MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training |\n",
    "| 2103.00020.pdf | Learning Transferable Visual Models From Natural Language Supervision |\n",
    "| 2407.01449.pdf | ColPali: Efficient Document Retrieval with Vision Language Models |\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(table))\n",
    "\n",
    "# This cell creates and displays a Markdown table with PDF paths and titles for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
